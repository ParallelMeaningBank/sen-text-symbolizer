###############################################################################

# This is the Producefile for running the PMB pipeline. For retraining models,
# use retrain.ini.

### NUTS AND BOLTS ############################################################

[]
prelude =
	import errno
	import os
	import subprocess

	def makedirs(path):
		try:
			os.makedirs(path)
		except OSError as error:
			if error.errno != errno.EEXIST:
				raise error

	def sync_bows(part, doc_id, lang, layer):
		"""
		Makes the file out/pPART/dDOC_ID/LANG.LAYER.bows up to date with
		information from the database. Does not change its timestamp if
		its contents do not change. Returns True if there were changes,
		False otherwise.
		"""
		makedirs('out/p{}/d{}'.format(part, doc_id))
		filename = 'out/p{}/d{}/{}.{}.bows'.format(part, doc_id, lang, layer)
		bowlist = subprocess.check_output(['./src/python/bows_tsv.py', part, doc_id, lang, layer]).decode('UTF-8')
		try:
			with open(filename, encoding='UTF-8') as f:
				old_bowlist = f.read()
			if old_bowlist == bowlist:
				return False
		except FileNotFoundError:
			pass
		with open(filename, 'w', encoding='UTF-8') as f:
			f.write(bowlist)
		return True

# Dummy task. Targets depending on this will be reproduced on every invocation.
[dummy]
type = task

### TOKENIZATION ##############################################################
# Tokenize using Elephant for all languages, add BoWs and make different output formats

[out/p%{part}/d%{doc_id}/%{lang}.tok.iob.noncorr]
dep.raw = raw/p%{part}/d%{doc_id}/%{lang}.raw
dep.elephant = ext/elephant/elephant
dep.model = retrain/tok.iob/%{lang}.model
recipe =
	set -e
	set -o pipefail
	mkdir -p out/p%{part}/d%{doc_id}
	export PATH=ext/elephant:ext/elephant/ext:$PATH
	cat %{raw} | %{elephant} -m %{model} -f iob | sed -e 's/\t/ /' > %{target} 2> %{target}.log

[out/p%{part}/d%{doc_id}/%{lang}.tok.iob]
dep.noncorr = out/p%{part}/d%{doc_id}/%{lang}.tok.iob.noncorr
dep.bows = ./src/python/bows_tokenization_iob.py
deps = %{'dummy' if sync_bows(part, doc_id, lang, 'tok.iob') else ''}
recipe =
	set -e
	set -o pipefail
	cat %{noncorr} | %{bows} -c config/config.ini -p %{part} -d %{doc_id} -l %{lang} | ./src/python/tabfixer.py > %{target} 2> %{target}.log

[out/p%{part}/d%{doc_id}/%{lang}.tok.off]
dep.iob = out/p%{part}/d%{doc_id}/%{lang}.tok.iob
dep.iob2off = src/python/iob2off.py
recipe = cat %{iob} | ./%{iob2off} > %{target}

[out/p%{part}/d%{doc_id}/%{lang}.tok]
dep.off = out/p%{part}/d%{doc_id}/%{lang}.tok.off
dep.off2tok = src/python/off2tok.py
recipe = cat %{off} | ./%{off2tok} > %{target}

### SENTENCE ALIGNMENT ########################################################

# We do not have a sentence aligner yet, so just create a basic 1-to-1 sentence alignment, and apply BoWs.
[out/p%{part}/d%{doc_id}/%{lang}.sentalign.noncorr]
dep.off_english = out/p%{part}/d%{doc_id}/en.tok.off
dep.off_foreign = out/p%{part}/d%{doc_id}/%{lang}.tok.off
recipe = src/python/sentence_alignment_121.py %{off_english} %{off_foreign} > %{target}

[out/p%{part}/d%{doc_id}/%{lang}.sentalign]
dep.noncorr = out/p%{part}/d%{doc_id}/%{lang}.sentalign.noncorr
dep.bows = ./src/python/bows_sentence_alignment.py
deps = %{'dummy' if sync_bows(part, doc_id, lang, 'sentalign') else ''}
recipe = cat %{noncorr} | %{bows} -p %{part} -d %{doc_id} -l %{lang} > %{target}

### POS TAGGING ###############################################################

# Only for English and without applying BOWs, helping morpha find the lemmas,
# also helping with finding default WordNet senses.
# POS-tagger cannot handle certain quotes or vertical slash, so these are replaced beforehand.
[out/p%{part}/d%{doc_id}/en.pos.noncorr]
dep.tok = out/p%{part}/d%{doc_id}/en.tok
dep.pos = ext/candc/bin/pos
dep.model = ext/candc/models/boxer/pos
recipe =
	set -o pipefail
	cat %{tok} | sed -e "s/[‘’]/'/g" | sed -e 's/[“”]/"/g' | sed -e 's/|/\//g' | ./%{pos} --maxwords 1000 --model %{model} > %{target} 2> %{target}.log

[out/p%{part}/d%{doc_id}/en.pos.noncorr.cols]
dep.pos = out/p%{part}/d%{doc_id}/en.pos.noncorr
dep.tok2cols = src/python/tok2cols.py
recipe = cat %{pos} | %{tok2cols} > %{target}

### LEMMATIZATION #############################################################
# Only for English, do lemmatization with Morpha

[out/p%{part}/d%{doc_id}/en.morpha]
dep.pos = out/p%{part}/d%{doc_id}/en.pos.noncorr
dep.morpha = ext/morph/morpha
dep.verbstem = ext/morph/verbstem.list
dep.pos2morpha = src/python/pos2morpha.py
recipe =
	set -o pipefail
	cat %{pos} | ./%{pos2morpha} | %{morpha} -f %{verbstem} > %{target} 2> %{target}.log

[out/p%{part}/d%{doc_id}/en.lemma.noncorr]
dep.pos = out/p%{part}/d%{doc_id}/en.pos.noncorr
dep.morpha = out/p%{part}/d%{doc_id}/en.morpha
dep.morpha2lemma = src/python/morpha2lemma.py
dep.lemma2cols = src/python/lemma2cols.py
recipe =
	set -o pipefail
	./%{morpha2lemma} %{pos} %{morpha} | ./%{lemma2cols} > %{target} 2> %{target}.log

[out/p%{part}/d%{doc_id}/%{lang}.lemma]
dep.noncorr = out/p%{part}/d%{doc_id}/%{lang}.lemma.noncorr
dep.off = out/p%{part}/d%{doc_id}/%{lang}.tok.off
dep.bows = ./src/python/bows_tags_cols.py
deps = %{'dummy' if sync_bows(part, doc_id, lang, 'lemma') else ''}
recipe =
	cat %{noncorr} | %{bows} -y lemma -c config/config.ini -t %{off} -p %{part} -d %{doc_id} -l %{lang} > %{target} 2> %{target}.log

### SEMANTIC TAGGING ##########################################################

# Currently only for English, semantic tags from the DNN-based semtagger
# TODO Support for all languages
[out/p%{part}/d%{doc_id}/en.semtag.noncorr]
dep.tok = out/p%{part}/d%{doc_id}/en.tok
dep.semtagger = src/python/semtagger.py
dep.model = models/semtag/semtag_dbgru_polyglot.weights
recipe = cat %{tok} | %{semtagger} --model models/semtag/semtag_bgru_ntagset --index-dict models/semtag/semtag_bgru_ntagset.w2id --tag-dict models/semtag/tag_to_id_ntagset.txt --maxlen 75 > %{target} 2> %{target}.log

[out/p%{part}/d%{doc_id}/%{lang}.semtag]
dep.noncorr = out/p%{part}/d%{doc_id}/%{lang}.semtag.noncorr
dep.off = out/p%{part}/d%{doc_id}/%{lang}.tok.off
dep.bows = ./src/python/bows_tags_cols.py
deps = %{'dummy' if sync_bows(part, doc_id, lang, 'semtag') else ''}
recipe = cat %{noncorr} | %{bows} -y semtag -c config/config.ini -t %{off} -p %{part} -d %{doc_id} -l %{lang} > %{target} 2> %{target}.log

### SYMBOLIZATION ########################################################

# Symbolizer, currently support English only
[out/p%{part}/d%{doc_id}/%{lang}.symbol]
dep.semtag = out/p%{part}/d%{doc_id}/%{lang}.semtag
#dep.symbol = out/p%{part}/d%{doc_id}/%{lang}.symbol
dep.symbolizer = ./src/python/sen_symbolizer.py
dep.symdatadir = ./models/symbol/tmp
dep.symtraindir = ./models/symbol/chkpnt
#recipe =
#	%{symbolizer} --data_dir %{symdatadir} --train_dir %{symtraindir} --sem_file %{semtag} --sym_file %{symbol}> %{target} 2> %{target}.log
recipe =
	%{symbolizer} --decode --data_dir %{symdatadir} --train_dir %{symtraindir} --sem_file %{semtag} > %{target} 2> %{target}.log

### WORD SENSE TAGGING ########################################################

# Initial annotation: choose the default sense for the given lemma
[out/p%{part}/d%{doc_id}/en.senseid.noncorr]
dep.lemma = out/p%{part}/d%{doc_id}/en.lemma
dep.pos = out/p%{part}/d%{doc_id}/en.pos.noncorr.cols
dep.lemmapos2defaultsenseid = ./src/python/lemmapos2defaultsenseid.py
recipe = paste <(cat %{lemma} | cut -f 1) <(cat %{pos} | cut -f 1) | %{lemmapos2defaultsenseid} > %{target} 2> %{target}.log

# Apply WordNet BOWs
[out/p%{part}/d%{doc_id}/en.senseid]
dep.noncorr = out/p%{part}/d%{doc_id}/en.senseid.noncorr
dep.off = out/p%{part}/d%{doc_id}/en.tok.off
dep.bows = ./src/python/bows_tags_cols.py
deps = %{'dummy' if sync_bows(part, doc_id, 'en', 'senseid') else ''}
recipe = cat %{noncorr} | %{bows} -y senseid -c config/config.ini -t %{off} -p %{part} -d %{doc_id} -l en > %{target} 2> %{target}.log

# Convert sense IDs to sense numbers (Boxer needs them)
[out/p%{part}/d%{doc_id}/en.sense]
dep.senseid = out/p%{part}/d%{doc_id}/en.senseid
dep.lemma = out/p%{part}/d%{doc_id}/en.lemma
dep.senseid2sense = ./src/python/senseid2sense.py
recipe = paste <(cat %{lemma} | cut -f 1) %{senseid} | %{senseid2sense} > %{target} 2> %{target}.log

### SEMANTIC ROLE LABELING ###################################################

# We do not have a role labeler yet, so just create as many empty lines as
# there are tokens, later fill those lines where we have BOWs. Boxer will fill
# in the remaining gaps.
[out/p%{part}/d%{doc_id}/%{lang}.verbnet.noncorr]
dep.off = out/p%{part}/d%{doc_id}/%{lang}.tok.off
recipe = cat %{off} | sed -e 's/.*//' > %{target} 2> %{target}.log

[out/p%{part}/d%{doc_id}/%{lang}.verbnet]
dep.noncorr = out/p%{part}/d%{doc_id}/%{lang}.verbnet.noncorr
dep.off = out/p%{part}/d%{doc_id}/%{lang}.tok.off
dep.bows = ./src/python/bows_tags_cols.py
deps = %{'dummy' if sync_bows(part, doc_id, lang, 'verbnet') else ''}
recipe = cat %{noncorr} | %{bows} -y verbnet -c config/config.ini -t %{off} -p %{part} -d %{doc_id} -l %{lang} > %{target} 2> %{target}.log

### RELATION TAGGING ##########################################################

# We do not have a relation tagger yet, so just create as many empty lines as
# there are tokens, later fill those lines where we have BOWs. Boxer will fill
# in the remaining gaps.
[out/p%{part}/d%{doc_id}/en.relation.noncorr]
dep.off = out/p%{part}/d%{doc_id}/en.tok.off
recipe = cat %{off} | sed -e 's/.*//' > %{target}

[out/p%{part}/d%{doc_id}/%{lang}.relation]
dep.noncorr = out/p%{part}/d%{doc_id}/%{lang}.relation.noncorr
dep.off = out/p%{part}/d%{doc_id}/%{lang}.tok.off
dep.bows = ./src/python/bows_tags_cols.py
deps = %{'dummy' if sync_bows(part, doc_id, lang, 'relation') else ''}
recipe = cat %{noncorr} | %{bows} -y relation -c config/config.ini -t %{off} -p %{part} -d %{doc_id} -l %{lang} > %{target}

### COREFERENCE ANNOTATION ####################################################

# We do not have a coreference tool yet, so just create as many empty lines as
# there are tokens, later fill those lines where we have BOWs. Boxer will fill
# in the remaining gaps.
[out/p%{part}/d%{doc_id}/%{lang}.antecedent.noncorr]
dep.off = out/p%{part}/d%{doc_id}/%{lang}.tok.off
recipe = cat %{off} | sed -e 's/.*//' > %{target} 2> %{target}.log

[out/p%{part}/d%{doc_id}/%{lang}.antecedent]
dep.noncorr = out/p%{part}/d%{doc_id}/%{lang}.antecedent.noncorr
dep.off = out/p%{part}/d%{doc_id}/%{lang}.tok.off
dep.bows = ./src/python/bows_tags_cols.py
deps = %{'dummy' if sync_bows(part, doc_id, lang, 'antecedent') else ''}
recipe = cat %{noncorr} | %{bows} -y antecedent -c config/config.ini -t %{off} -p %{part} -d %{doc_id} -l %{lang} > %{target} 2> %{target}.log

### SUPERTAGGING ##############################################################

# We leave the supertagging mainly to the parser, but if there is a BOW, we
# constrain it to use that supertag.
[out/p%{part}/d%{doc_id}/%{lang}.super.noncorr]
dep.off = out/p%{part}/d%{doc_id}/%{lang}.tok.off
recipe = cat %{off} | sed -e 's/.*//' > %{target} 2> %{target}.log

[out/p%{part}/d%{doc_id}/%{lang}.super]
dep.noncorr = out/p%{part}/d%{doc_id}/%{lang}.super.noncorr
dep.off = out/p%{part}/d%{doc_id}/%{lang}.tok.off
dep.bows = ./src/python/bows_tags_cols.py
deps = %{'dummy' if sync_bows(part, doc_id, lang, 'super') else ''}
recipe = cat %{noncorr} | %{bows} -y super -c config/config.ini -t %{off} -p %{part} -d %{doc_id} -l %{lang} > %{target} 2> %{target}.log

### PARSING ###################################################################

# TODO: just creating a scaffold for now
[out/p%{part}/d%{doc_id}/%{lang}.parse]
cond = %{lang in ('de', 'it', 'nl')}
recipe =
	cat <<EOF > %{target}
	:- op(601, xfx, (/)).
	:- op(601, xfx, (\)).
	:- multifile ccg/2, id/2.
	:- discontiguous ccg/2, id/2.

	EOF

# TODO include span constraints (e.g. "there is a constituent from 7 22")
[out/p%{part}/d%{doc_id}/%{lang}.parse]
dep.tok = out/p%{part}/d%{doc_id}/%{lang}.tok
dep.super = out/p%{part}/d%{doc_id}/%{lang}.super
dep.add_supertag_constraints = ./src/python/add_supertag_constraints.py
dep.easyccg = ext/easyccg/easyccg.jar
dep.model = retrain/parse/%{lang}.model
dep.cac_renumber = src/python/cac_renumber.py
dep.missing_sentence_detector = ./src/python/missing_sentences.py
recipe =
	set -e
	set -o pipefail
	cat %{tok} | %{add_supertag_constraints} %{super} | ~/java-9-oracle/bin/java -jar %{easyccg} -i supertagconstrained -m %{model} --unrestrictedRules -o boxer > %{target}
	cat %{target} | %{missing_sentence_detector} %{tok} > out/p%{part}/d%{doc_id}/%{lang}.missing_sentences.log

# Add tags from other layers to parse
# HACK: using (non-corrected) POS tags for Explorer's search function
[out/p%{part}/d%{doc_id}/en.parse.tags]
dep.parse = out/p%{part}/d%{doc_id}/en.parse
dep.insert = ./src/python/cac_addtags.py
deps = src/python/caclib.py
dep.off = out/p%{part}/d%{doc_id}/en.tok.off
dep.pos = out/p%{part}/d%{doc_id}/en.pos.noncorr.cols
dep.semtag = out/p%{part}/d%{doc_id}/en.semtag
dep.lemma = out/p%{part}/d%{doc_id}/en.lemma
dep.verbnet = out/p%{part}/d%{doc_id}/en.verbnet
recipe = cat %{parse} | %{insert} %{off} from <(cut -d ' ' -f 1 %{off}) to <(cut -d ' ' -f 2 %{off}) pos %{pos} sem %{semtag} lemma %{lemma} verbnet %{verbnet} > %{target}

# Add tags from other layers to parse
# HACK: using (non-corrected) POS tags for Explorer's search function
[out/p%{part}/d%{doc_id}/%{lang}.parse.tags]
dep.parse = out/p%{part}/d%{doc_id}/%{lang}.parse
dep.insert = ./src/python/cac_addtags.py
deps = src/python/caclib.py
dep.off = out/p%{part}/d%{doc_id}/%{lang}.tok.off
dep.semtag = out/p%{part}/d%{doc_id}/%{lang}.semtag
dep.symbol = out/p%{part}/d%{doc_id}/%{lang}.symbol
dep.lemma = out/p%{part}/d%{doc_id}/%{lang}.lemma
dep.verbnet = out/p%{part}/d%{doc_id}/%{lang}.verbnet
recipe = cat %{parse} | %{insert} %{off} from <(cut -d ' ' -f 1 %{off}) to <(cut -d ' ' -f 2 %{off}) sem %{semtag} lemma %{lemma} verbnet %{verbnet} > %{target}

# We also make a file that contains just the category for each token so we can
# easily project the categories to other languages.

[out/p%{part}/d%{doc_id}/en.cats]
dep.parse = out/p%{part}/d%{doc_id}/en.parse
dep.parse2cats = ./src/python/parse2cats.py
recipe = cat %{parse} | %{parse2cats} > %{target}

### BOXING ####################################################################

# Run Boxer for derivations
[out/p%{part}/d%{doc_id}/%{lang}.der.xml.incomplete]
dep.parse = out/p%{part}/d%{doc_id}/%{lang}.parse.tags
dep.boxer = ext/boxer/boxer2
recipe = %{boxer} --input %{parse} --semantics der --resolve --tense --instantiate --modal --theory sdrt --copula false --nn --mwe yes --elimeq --roles verbnet --format xml --warnings false --output %{target} 2> %{target}.log

# Create an XML file containing all tags, used for adding missing derivation placeholders
[out/p%{part}/d%{doc_id}/%{lang}.tok.xml]
dep.off = out/p%{part}/d%{doc_id}/%{lang}.tok.off
dep.super = out/p%{part}/d%{doc_id}/%{lang}.super
dep.semtag = out/p%{part}/d%{doc_id}/%{lang}.semtag
dep.symbol = out/p%{part}/d%{doc_id}/%{lang}.symbol
dep.lemma = out/p%{part}/d%{doc_id}/%{lang}.lemma
dep.verbnet = out/p%{part}/d%{doc_id}/%{lang}.verbnet
dep.relation = out/p%{part}/d%{doc_id}/%{lang}.relation
dep.antecedent = out/p%{part}/d%{doc_id}/%{lang}.antecedent
dep.cols2xml = ./src/python/cols2xml.py
recipe = paste <(cut -d ' ' -f 3 %{off}) <(cut -d ' ' -f 4- %{off}) <(cut -d ' ' -f 1 %{off}) <(cut -d ' ' -f 2 %{off}) %{super} <(cut -f 1 %{semtag}) %{lemma} %{verbnet} %{relation} %{antecedent} | %{cols2xml} from to super sem lemma verbnet relation antecedent > %{target} 2> %{target}.log

# Add placeholders for sentences missing derivations to Boxer output
[out/p%{part}/d%{doc_id}/%{lang}.der.xml]
dep.incomplete = out/p%{part}/d%{doc_id}/%{lang}.der.xml.incomplete
dep.tokxml = out/p%{part}/d%{doc_id}/%{lang}.tok.xml
dep.dermerge = ./src/python/dermerge.py
recipe = %{dermerge} %{incomplete} %{tokxml} > %{target} 2> %{target}.log

# Run Boxer for DRS
[out/p%{part}/d%{doc_id}/%{lang}.drs.xml]
dep.parse = out/p%{part}/d%{doc_id}/%{lang}.parse.tags
dep.boxer = ext/boxer/boxer2
recipe = %{boxer} --input %{parse} --semantics pdrs --resolve --tense --instantiate --modal --theory sdrt --copula false --nn --mwe yes --elimeq --roles verbnet --format xml --output %{target} 2> %{target}.log

### UPDATING SEMANTIC LEXICON #################################################

[out/p%{part}/d%{doc_id}/%{lang}.semlex]
dep.extract = ./src/python/semlex_extract.py
dep.derxml = out/p%{part}/d%{doc_id}/%{lang}.der.xml
dep.update = ./src/python/semlex_update.py
recipe = 
	%{extract} -i %{derxml} -c config/config.ini > %{target} 2> %{target}.log

### WORD ALIGNMENTS ###########################################################

[out/p%{part}/d%{doc_id}/%{lang}.wordalign.noncorr]
cond = %{lang in ('de', 'it', 'nl')}
dep.wordalign = retrain/wordalign/%{lang}-en.wordalign
recipe = cat %{wordalign} | grep '^%{part}/%{doc_id}' | cut -f2-5 > %{target}

# TODO: apply word alignment BOWs
[out/p%{part}/d%{doc_id}/%{lang}.wordalign]
cond = %{lang in ('de', 'it', 'nl')}
dep.noncorr = out/p%{part}/d%{doc_id}/%{lang}.wordalign.noncorr
recipe = cp %{noncorr} %{target}

### TAGS FOR DE, IT, NL (VIA WORD ALIGNMENTS) #################################

[out/p%{part}/d%{doc_id}/%{lang}.%{layer}.noncorr]
cond = %{lang in ('de', 'it', 'nl') and layer in ('semtag', 'lemma', 'verbnet', 'relation', 'super')}
dep.en = out/p%{part}/d%{doc_id}/en.%{layer}
dep.wordalign = out/p%{part}/d%{doc_id}/%{lang}.wordalign
dep.engoff = out/p%{part}/d%{doc_id}/en.tok.off
dep.foroff = out/p%{part}/d%{doc_id}/%{lang}.tok.off
dep.project_tags = ./src/python/project_tags.py
recipe = cat %{en} | %{project_tags} -a %{wordalign} -t %{engoff} -T %{foroff} > %{target}

### MASTER ####################################################################

[out/p%{part}/d%{doc_id}/en.master]
type = task
dep.semlex = out/p%{part}/d%{doc_id}/en.semlex
dep.drs = out/p%{part}/d%{doc_id}/en.drs.xml

[out/p%{part}/d%{doc_id}/%{lang}.master]
type = task
dep.sentalign = out/p%{part}/d%{doc_id}/%{lang}.sentalign
dep.wordalign = out/p%{part}/d%{doc_id}/%{lang}.wordalign
dep.tok = out/p%{part}/d%{doc_id}/%{lang}.tok
dep.der = out/p%{part}/d%{doc_id}/%{lang}.der.xml
