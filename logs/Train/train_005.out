Preparing WMT data in tmp_005
en_train: tmp_005/2m_time-text_0.1_0.1_all-ws-train.ids1000.word
fr_train: tmp_005/2m_time-text_0.1_0.1_all-ws-train.ids1000.sym
en_dev: tmp_005/500k_time-text_0.1_0.1_all-ws-dev.ids1000.word
fr_dev: tmp_005/500k_time-text_0.1_0.1_all-ws-dev.ids1000.sym

Creating 3 layers of 860 units.
Created model with fresh parameters.
Reading development and training data (limit: 0).
  reading data line 100000
  reading data line 200000
  reading data line 300000
  reading data line 400000
  reading data line 500000
  reading data line 100000
  reading data line 200000
  reading data line 300000
  reading data line 400000
  reading data line 500000
  reading data line 600000
  reading data line 700000
  reading data line 800000
  reading data line 900000
  reading data line 1000000
  reading data line 1100000
  reading data line 1200000
  reading data line 1300000
  reading data line 1400000
  reading data line 1500000
  reading data line 1600000
  reading data line 1700000
  reading data line 1800000
  reading data line 1900000
  reading data line 2000000
Reading completed. Now estimating buckets and sizes.
_buckets[(28, 7)] 
train_bucket_sizes: [2000000] 
train_total_size: 2000000.0
global step 200 learning rate 0.3000 step-time 2.11 perplexity 14.19
  eval: bucket 0 perplexity 1.84
max_preplexity_count: 0 
 prexs: [1.841948079656621]
global step 400 learning rate 0.3000 step-time 2.09 perplexity 1.61
  eval: bucket 0 perplexity 1.41
max_preplexity_count: 0 
 prexs: [1.408401267564491]
global step 600 learning rate 0.3000 step-time 2.14 perplexity 1.26
  eval: bucket 0 perplexity 1.13
max_preplexity_count: 1 
 prexs: [1.1269586306208301]
global step 800 learning rate 0.3000 step-time 2.11 perplexity 1.39
  eval: bucket 0 perplexity 1.08
max_preplexity_count: 1 
 prexs: [1.0797254028435106]
global step 1000 learning rate 0.3000 step-time 2.14 perplexity 1.07
  eval: bucket 0 perplexity 1.03
max_preplexity_count: 1 
 prexs: [1.0300080384244827]
global step 1200 learning rate 0.3000 step-time 2.22 perplexity 1.03
  eval: bucket 0 perplexity 1.02
max_preplexity_count: 1 
 prexs: [1.0217774793535108]
global step 1400 learning rate 0.3000 step-time 2.12 perplexity 1.02
  eval: bucket 0 perplexity 1.01
max_preplexity_count: 1 
 prexs: [1.0130092519967535]
